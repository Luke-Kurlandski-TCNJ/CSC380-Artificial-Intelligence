{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b84ee9b2",
   "metadata": {},
   "source": [
    "# 2.1 Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c52a5b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "66a16d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 20)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first two bit A and B, remaining 3 bit is operator identifier\n",
    "X = np.array([\n",
    "            #AND \n",
    "            [0, 0, 0, 0, 0],\n",
    "            [0, 1, 0, 0, 0],\n",
    "            [1, 0, 0, 0, 0],\n",
    "            [1, 1, 0, 0, 0],\n",
    "            #OR    \n",
    "            [0, 0, 0, 0, 1],\n",
    "            [0, 1, 0, 0, 1],\n",
    "            [1, 0, 0, 0, 1],\n",
    "            [1, 1, 0, 0, 1],\n",
    "            #XOR\n",
    "            [0, 0, 0, 1, 0],\n",
    "            [0, 1, 0, 1, 0],\n",
    "            [1, 0, 0, 1, 0],\n",
    "            [1, 1, 0, 1, 0],\n",
    "            #NAND\n",
    "            [0, 0, 0, 1, 1],\n",
    "            [0, 1, 0, 1, 1],\n",
    "            [1, 0, 0, 1, 1],\n",
    "            [1, 1, 0, 1, 1],\n",
    "            #NOR\n",
    "            [0, 0, 1, 0, 0],\n",
    "            [0, 1, 1, 0, 0],\n",
    "            [1, 0, 1, 0, 0],\n",
    "            [1, 1, 1, 0, 0],\n",
    "            ]).T\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c82fb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#target output        AND         OR           XOR       NAND         NOR\n",
    "Y = np.array([[0, 0, 0, 1],[0, 1, 1, 1], [0, 1, 1, 0],[1, 1, 1, 0], [1, 0, 0, 0]])\n",
    "Y = Y.reshape(1,20)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac26e905",
   "metadata": {},
   "source": [
    "## Sigmoid as Activation Function\n",
    " *  Ensures that the network is capable of computing all sorts of complex functions\n",
    " *  it helps push the output towards 0 or 1 (classifying into 2 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d65c41cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee9470bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights and bias \n",
    "def init_weights(input_features, n_hidden, output_features):\n",
    "    # Weights \n",
    "    W1 = np.random.randn(n_hidden, input_features)\n",
    "    W2 = np.random.randn(output_features, n_hidden)\n",
    "    \n",
    "    # bias \n",
    "    b1 = np.zeros((n_hidden, 1))\n",
    "    b2 = np.zeros((output_features, 1))\n",
    "\n",
    "    \n",
    "    weights = {\"W1\" : W1, \"b1\" : b1, \n",
    "               \"W2\" : W2, \"b2\" : b2}\n",
    "    return weights "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a4c1cc",
   "metadata": {},
   "source": [
    "#### Forward Propagation\n",
    "* forward pass , calculation and storage of intermediate variables for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "621d3643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to perform forward propagation\n",
    "def forward_propagation(X, Y, weights):\n",
    "    m = X.shape[1] #number of samples\n",
    "    \n",
    "    #extract weights \n",
    "    W1 = weights[\"W1\"]\n",
    "    b1 = weights[\"b1\"]\n",
    "    W2 = weights[\"W2\"]\n",
    "    b2 = weights[\"b2\"]\n",
    "    \n",
    "    #calculate output\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    #save the parameters \n",
    "    params = (Z1, A1, W1, b1, Z2, A2, W2, b2)\n",
    "    \n",
    "    #calculate cost function \n",
    "    cost = np.log(A2)* Y + np.log(1 - A2)*(1 - Y)\n",
    "    cost = -np.sum(cost) / m\n",
    "\n",
    "    return cost, params, A2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818c0d24",
   "metadata": {},
   "source": [
    "#### Backward Prpagation\n",
    "* Calulating gradient of neural network parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "983b671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to perform Backward propagation\n",
    "def backward_propagation(X, Y, params):\n",
    "    m = X.shape[1]\n",
    "    #extract parameters \n",
    "    (Z1, A1, W1, b1, Z2, A2, W2, b2) = params\n",
    "    \n",
    "    #calculate output error\n",
    "    dZ2 = A2 - Y\n",
    "    \n",
    "    #caculate gradient of second weights \n",
    "    dW2 = np.dot(dZ2, A1.T) / m  \n",
    "    db2 = np.sum(dZ2, axis = 1, keepdims = True )\n",
    "    \n",
    "    #calculates error of hidden layer \n",
    "    dA1 = np.dot(W2.T, dZ2)\n",
    "    dZ1 = dA1 * A1 * (1 - A1)\n",
    "    \n",
    "    #find gradients of first weights\n",
    "    dW1 = np.dot(dZ1, X.T)\n",
    "    db1 = np.sum(dZ1, axis = 1, keepdims = True) / m\n",
    "    \n",
    "    #store gradients \n",
    "    gradients = {\"dW2\": dW2, \"db2\" : db2,\n",
    "                 \"dW1\": dW1, \"db1\": db1 }\n",
    "    \n",
    "    return gradients \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d64249",
   "metadata": {},
   "source": [
    "#### Updating Weights using gradients as well as learning rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a25e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to update weights, lr = learning rate \n",
    "def update_parameters(weights, gradients, lr): \n",
    "    weights[\"W1\"] = weights[\"W1\"] - lr * gradients[\"dW1\"]\n",
    "    weights[\"b1\"] = weights[\"b1\"] - lr * gradients[\"db1\"]\n",
    "    weights[\"W2\"] = weights[\"W2\"] - lr * gradients[\"dW2\"]\n",
    "    weights[\"b2\"] = weights[\"b2\"] - lr * gradients[\"db2\"]\n",
    "    \n",
    "    return weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9c5465e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure parameters \n",
    "n_hidden = 5 # number of neurons in hidden layer\n",
    "input_features = X.shape[0] #number of input neurons\n",
    "output_features = Y.shape[0] \n",
    "weights = init_weights(input_features, n_hidden, output_features) \n",
    "epochs = 10000\n",
    "lr = 0.01\n",
    "cost = np.zeros((epochs, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "67f4912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train network \n",
    "for i in range(epochs):\n",
    "    cost[i, 0], params, A = forward_propagation(X, Y, weights)\n",
    "    gradients = backward_propagation(X, Y, params)\n",
    "    weights = update_parameters(weights, gradients, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dc70c47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :90.0 %\n"
     ]
    }
   ],
   "source": [
    "#testing on training set \n",
    "cost, _, A = forward_propagation(X, Y, weights ) #predict values \n",
    "y_pred = (A > 0.5) * 1.0 #find labels from probabilities \n",
    "#calculate accuracy \n",
    "score = 1 - np.mean(np.abs(y_pred - Y))\n",
    "print(\"Accuracy :{} %\".format(score*100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "835bf6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# sample testing \n",
    "X_test = np.array([[1,1,0,0,0], #AND \n",
    "                   [1,1,0,0,1], #OR\n",
    "                   [1,1,0,1,0], #XOR\n",
    "                   [1,1,0,1,1], #NAND\n",
    "                   [1,1,1,0,0]  #NOR\n",
    "                   ])\n",
    "y_true = np.array([1, 1, 0, 0,0])  # target values for sample input\n",
    "_,_, A2 = forward_propagation(X_test, y_true, weights)\n",
    "y_pred = (A2 > 0.5) * 1\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6c8ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330dae57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
